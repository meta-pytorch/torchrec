
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Data Types &#8212; TorchRec 1.0.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=36fba2ff" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=8d563738"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'datatypes-api-reference';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modules" href="modules-api-reference.html" />
    <link rel="prev" title="Setting up TorchRec" href="setup-torchrec.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
</style>


<style>
  @media (min-width: 1100px) {
    .site-footer {
      height: 300px !important;
    }
  }
</style>

<link rel="stylesheet" type="text/css" href="_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NPLPKN5G" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-NPLPKN5G');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', '1.0.0');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/meta-pytorch/torchrec" class="pytorch-body">
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="overview.html">
    TorchRec Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="high-level-arch.html">
    TorchRec High Level Architecture
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="concepts.html">
    TorchRec Concepts
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="setup-torchrec.html">
    Setting up TorchRec
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Data Types
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="modules-api-reference.html">
    Modules
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="planner-api-reference.html">
    Planner
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="model-parallel-api-reference.html">
    Model Parallel
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="inference-api-reference.html">
    Inference
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/meta-pytorch/torchrec" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchrec/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="overview.html">
    TorchRec Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="high-level-arch.html">
    TorchRec High Level Architecture
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="concepts.html">
    TorchRec Concepts
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="setup-torchrec.html">
    Setting up TorchRec
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Data Types
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="modules-api-reference.html">
    Modules
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="planner-api-reference.html">
    Planner
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="model-parallel-api-reference.html">
    Model Parallel
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="inference-api-reference.html">
    Inference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/meta-pytorch/torchrec" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchrec/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">Data Types</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Data Types">
        <meta itemprop="position" content="1">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="data-types">
<h1>Data Types<a class="headerlink" href="#data-types" title="Link to this heading">#</a></h1>
<p>TorchRec contains data types for representing embedding, otherwise known as sparse features.
Sparse features are typically indices that are meant to be fed into embedding tables. For a given
batch, the number of embedding lookup indices are variable. Therefore, there is a need for a <strong>jagged</strong>
dimension to represent the variable amount of embedding lookup indices for a batch.</p>
<p>This section covers the classes for the 3 TorchRec data types for representing sparse features:
<strong>JaggedTensor</strong>, <strong>KeyedJaggedTensor</strong>, and <strong>KeyedTensor</strong>.</p>
<dl class="py class" id="module-torchrec.sparse.jagged_tensor">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchrec.sparse.jagged_tensor.</span></span><span class="sig-name descname"><span class="pre">JaggedTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="Link to this definition">#</a></dt>
<dd><p>Represents an (optionally weighted) jagged tensor.</p>
<p>A <cite>JaggedTensor</cite> is a tensor with a <em>jagged dimension</em> which is dimension whose
slices may be of different lengths. See <cite>KeyedJaggedTensor</cite> for full example.</p>
<p>Implementation is torch.jit.script-able.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will NOT do input validation as it’s expensive, you should always pass in the
valid lengths, offsets, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – values tensor in dense representation.</p></li>
<li><p><strong>weights</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – if values have weights. Tensor with same shape
as values.</p></li>
<li><p><strong>lengths</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – jagged slices, represented as lengths.</p></li>
<li><p><strong>offsets</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – jagged slices, represented as cumulative
offsets.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.device">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">device</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.device" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor device.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the device of the values tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.empty">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">is_weighted</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">torch.int32</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><span class="pre">JaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.empty" title="Link to this definition">#</a></dt>
<dd><p>Constructs an empty JaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>is_weighted</strong> (<em>bool</em>) – whether the JaggedTensor has weights.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>torch.device</em><em>]</em>) – device for JaggedTensor.</p></li>
<li><p><strong>values_dtype</strong> (<em>Optional</em><em>[</em><em>torch.dtype</em><em>]</em>) – dtype for values.</p></li>
<li><p><strong>weights_dtype</strong> (<em>Optional</em><em>[</em><em>torch.dtype</em><em>]</em>) – dtype for weights.</p></li>
<li><p><strong>lengths_dtype</strong> (<em>torch.dtype</em>) – dtype for lengths.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>empty JaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor">JaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.from_dense">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><span class="pre">JaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.from_dense" title="Link to this definition">#</a></dt>
<dd><p>Constructs <cite>JaggedTensor</cite> from list of tensors as values, with optional weights.
<cite>lengths</cite> will be computed, of shape (B,), where B is <cite>len(values)</cite> which
represents the batch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – a list of tensors for dense representation</p></li>
<li><p><strong>weights</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>torch.Tensor</em><em>]</em><em>]</em>) – if values have weights, tensor with
the same shape as values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>JaggedTensor created from 2D dense tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor">JaggedTensor</a></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">]),</span>
<span class="p">]</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">]),</span>
<span class="p">]</span>
<span class="n">j1</span> <span class="o">=</span> <span class="n">JaggedTensor</span><span class="o">.</span><span class="n">from_dense</span><span class="p">(</span>
    <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># j1 = [[1.0], [], [7.0, 8.0], [10.0, 11.0, 12.0]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.from_dense_lengths">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dense_lengths</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><span class="pre">JaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.from_dense_lengths" title="Link to this definition">#</a></dt>
<dd><p>Constructs <cite>JaggedTensor</cite> from values and lengths tensors, with optional weights.
Note that <cite>lengths</cite> is still of shape (B,), where B is the batch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – dense representation of values.</p></li>
<li><p><strong>lengths</strong> (<em>torch.Tensor</em>) – jagged slices, represented as lengths.</p></li>
<li><p><strong>weights</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – if values have weights, tensor with
the same shape as values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>JaggedTensor created from 2D dense tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor">JaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.lengths">
<span class="sig-name descname"><span class="pre">lengths</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.lengths" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor lengths. If not computed, compute it from offsets.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the lengths tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.lengths_or_none">
<span class="sig-name descname"><span class="pre">lengths_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.lengths_or_none" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor lengths. If not computed, return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the lengths tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.offsets">
<span class="sig-name descname"><span class="pre">offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.offsets" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor offsets. If not computed, compute it from lengths.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the offsets tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.offsets_or_none">
<span class="sig-name descname"><span class="pre">offsets_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.offsets_or_none" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor offsets. If not computed, return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the offsets tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.record_stream">
<span class="sig-name descname"><span class="pre">record_stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Stream</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.record_stream" title="Link to this definition">#</a></dt>
<dd><p>See <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html">https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><span class="pre">JaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to" title="Link to this definition">#</a></dt>
<dd><p>Move the JaggedTensor to the specified device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<em>torch.device</em>) – the device to move to.</p></li>
<li><p><strong>non_blocking</strong> (<em>bool</em>) – whether to perform the copy asynchronously.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the moved JaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor">JaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.to_dense">
<span class="sig-name descname"><span class="pre">to_dense</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_dense" title="Link to this definition">#</a></dt>
<dd><p>Constructs a dense-representation of the JT’s values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of tensors.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[torch.Tensor]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">jt</span> <span class="o">=</span> <span class="n">JaggedTensor</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">)</span>

<span class="n">values_list</span> <span class="o">=</span> <span class="n">jt</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>

<span class="c1"># values_list = [</span>
<span class="c1">#     torch.tensor([1.0, 2.0]),</span>
<span class="c1">#     torch.tensor([]),</span>
<span class="c1">#     torch.tensor([3.0]),</span>
<span class="c1">#     torch.tensor([4.0]),</span>
<span class="c1">#     torch.tensor([5.0]),</span>
<span class="c1">#     torch.tensor([6.0, 7.0, 8.0]),</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.to_dense_weights">
<span class="sig-name descname"><span class="pre">to_dense_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_dense_weights" title="Link to this definition">#</a></dt>
<dd><p>Constructs a dense-representation of the JT’s weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of tensors, <cite>None</cite> if no weights.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[List[torch.Tensor]]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">jt</span> <span class="o">=</span> <span class="n">JaggedTensor</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">)</span>

<span class="n">weights_list</span> <span class="o">=</span> <span class="n">jt</span><span class="o">.</span><span class="n">to_dense_weights</span><span class="p">()</span>

<span class="c1"># weights_list = [</span>
<span class="c1">#     torch.tensor([0.1, 0.2]),</span>
<span class="c1">#     torch.tensor([]),</span>
<span class="c1">#     torch.tensor([0.3]),</span>
<span class="c1">#     torch.tensor([0.4]),</span>
<span class="c1">#     torch.tensor([0.5]),</span>
<span class="c1">#     torch.tensor([0.6, 0.7, 0.8]),</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.to_padded_dense">
<span class="sig-name descname"><span class="pre">to_padded_dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desired_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_padded_dense" title="Link to this definition">#</a></dt>
<dd><p>Constructs a 2D dense tensor from the JT’s values of shape (B, N,).</p>
<p>Note that <cite>B</cite> is the length of self.lengths() and
<cite>N</cite> is the longest feature length or <cite>desired_length</cite>.</p>
<p>If <cite>desired_length</cite> &gt; <cite>length</cite> we will pad with <cite>padding_value</cite>, otherwise we
will select the last value at <cite>desired_length</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desired_length</strong> (<em>int</em>) – the length of the tensor.</p></li>
<li><p><strong>padding_value</strong> (<em>float</em>) – padding value if we need to pad.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>2d dense tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">jt</span> <span class="o">=</span> <span class="n">JaggedTensor</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">)</span>

<span class="n">dt</span> <span class="o">=</span> <span class="n">jt</span><span class="o">.</span><span class="n">to_padded_dense</span><span class="p">(</span>
    <span class="n">desired_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">padding_value</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># dt = [</span>
<span class="c1">#     [1.0, 2.0],</span>
<span class="c1">#     [10.0, 10.0],</span>
<span class="c1">#     [3.0, 10.0],</span>
<span class="c1">#     [4.0, 10.0],</span>
<span class="c1">#     [5.0, 10.0],</span>
<span class="c1">#     [6.0, 7.0],</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.to_padded_dense_weights">
<span class="sig-name descname"><span class="pre">to_padded_dense_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desired_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_padded_dense_weights" title="Link to this definition">#</a></dt>
<dd><p>Constructs a 2D dense tensor from the JT’s weights of shape (B, N,).</p>
<p>Note that <cite>B</cite> (batch size) is the length of self.lengths() and
<cite>N</cite> is the longest feature length or <cite>desired_length</cite>.</p>
<p>If <cite>desired_length</cite> &gt; <cite>length</cite> we will pad with <cite>padding_value</cite>, otherwise we
will select the last value at <cite>desired_length</cite>.</p>
<p>Like <cite>to_padded_dense</cite> but for the JT’s weights instead of values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>desired_length</strong> (<em>int</em>) – the length of the tensor.</p></li>
<li><p><strong>padding_value</strong> (<em>float</em>) – padding value if we need to pad.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>2d dense tensor, <cite>None</cite> if no weights.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[torch.Tensor]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">IntTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">jt</span> <span class="o">=</span> <span class="n">JaggedTensor</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">)</span>

<span class="n">d_wt</span> <span class="o">=</span> <span class="n">jt</span><span class="o">.</span><span class="n">to_padded_dense_weights</span><span class="p">(</span>
    <span class="n">desired_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">padding_value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># d_wt = [</span>
<span class="c1">#     [0.1, 0.2],</span>
<span class="c1">#     [1.0, 1.0],</span>
<span class="c1">#     [0.3, 1.0],</span>
<span class="c1">#     [0.4, 1.0],</span>
<span class="c1">#     [0.5, 1.0],</span>
<span class="c1">#     [0.6, 0.7],</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.values">
<span class="sig-name descname"><span class="pre">values</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.values" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the values tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.weights">
<span class="sig-name descname"><span class="pre">weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.weights" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor weights. If None, throw an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the weights tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.JaggedTensor.weights_or_none">
<span class="sig-name descname"><span class="pre">weights_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.JaggedTensor.weights_or_none" title="Link to this definition">#</a></dt>
<dd><p>Get JaggedTensor weights. If None, return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the weights tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchrec.sparse.jagged_tensor.</span></span><span class="sig-name descname"><span class="pre">KeyedJaggedTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="Link to this definition">#</a></dt>
<dd><p>Represents an (optionally weighted) keyed jagged tensor.</p>
<p>A <cite>KeyedJaggedTensor</cite> is a tensor with a <em>jagged dimension</em> which is dimension whose
slices may be of different lengths. Keyed on first dimension and jagged on the last
dimension.</p>
<p>Implementation is torch.jit.script-able.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keys</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – keys to the jagged Tensor.</p></li>
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – values tensor in dense representation.</p></li>
<li><p><strong>weights</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – if the values have weights. Tensor with the
same shape as values.</p></li>
<li><p><strong>lengths</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – jagged slices, represented as lengths.</p></li>
<li><p><strong>offsets</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – jagged slices, represented as cumulative
offsets.</p></li>
<li><p><strong>stride</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – number of examples per batch.</p></li>
<li><p><strong>stride_per_key_per_rank</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>torch.IntTensor</em><em>, </em><em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em><em>]</em><em>]</em>) – batch size (number of examples) per key per rank, with the outer list
representing the keys and the inner list representing the values.
Each value in the inner list represents the number of examples in the batch
from the rank of its index in a distributed context.</p></li>
<li><p><strong>length_per_key</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – start length for each key.</p></li>
<li><p><strong>offset_per_key</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – start offset for each key and final
offset.</p></li>
<li><p><strong>index_per_key</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em><em>]</em>) – index for each key.</p></li>
<li><p><strong>jt_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><em>JaggedTensor</em></a><em>]</em><em>]</em>) – dictionary of keys to JaggedTensors.
Allow ability to make to_dict() lazy/cacheable.</p></li>
<li><p><strong>inverse_indices</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em><em>]</em>) – inverse indices to
expand deduplicated embedding output for variable stride per key.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#              0       1        2  &lt;-- dim_1
# &quot;Feature0&quot;   [V0,V1] None    [V2]
# &quot;Feature1&quot;   [V3]    [V4]    [V5,V6,V7]
#   ^
#  dim_0

dim_0: keyed dimension (ie. `Feature0`, `Feature1`)
dim_1: optional second dimension (ie. batch size)
dim_2: The jagged dimension which has slice lengths between 0-3 in the above example

# We represent this data with following inputs:

values: torch.Tensor = [V0, V1, V2, V3, V4, V5, V6, V7]  # V == any tensor datatype
weights: torch.Tensor = [W0, W1, W2, W3, W4, W5, W6, W7]  # W == any tensor datatype
lengths: torch.Tensor = [2, 0, 1, 1, 1, 3]  # representing the jagged slice
offsets: torch.Tensor = [0, 2, 2, 3, 4, 5, 8]  # offsets from 0 for each jagged slice
keys: List[str] = [&quot;Feature0&quot;, &quot;Feature1&quot;]  # correspond to each value of dim_0
index_per_key: Dict[str, int] = {&quot;Feature0&quot;: 0, &quot;Feature1&quot;: 1}  # index for each key
offset_per_key: List[int] = [0, 3, 8]  # start offset for each key and final offset
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.concat">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kjt_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.concat" title="Link to this definition">#</a></dt>
<dd><p>Concatenates a list of KeyedJaggedTensors into a single KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>kjt_list</strong> (<em>List</em><em>[</em><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><em>KeyedJaggedTensor</em></a><em>]</em>) – list of KeyedJaggedTensors to be concatenated.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>concatenated KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.copy_">
<span class="sig-name descname"><span class="pre">copy_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kjt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.copy_" title="Link to this definition">#</a></dt>
<dd><p>Copies the values, weights, lengths, and offsets of the input KeyedJaggedTensor to the current KeyedJaggedTensor.
Assume host-side meta data like the keys, stride, stride_per_key, etc. are already ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kjt</strong> (<a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><em>KeyedJaggedTensor</em></a>) – input KeyedJaggedTensor.</p></li>
<li><p><strong>non_blocking</strong> (<em>bool</em>) – whether to perform the copy asynchronously.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>copied KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.device">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">device</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.device" title="Link to this definition">#</a></dt>
<dd><p>Returns the device of the KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>device of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">is_weighted</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths_dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">torch.int32</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty" title="Link to this definition">#</a></dt>
<dd><p>Constructs an empty KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>is_weighted</strong> (<em>bool</em>) – whether the KeyedJaggedTensor is weighted or not.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>torch.device</em><em>]</em>) – device on which the KeyedJaggedTensor will be placed.</p></li>
<li><p><strong>values_dtype</strong> (<em>Optional</em><em>[</em><em>torch.dtype</em><em>]</em>) – dtype of the values tensor.</p></li>
<li><p><strong>weights_dtype</strong> (<em>Optional</em><em>[</em><em>torch.dtype</em><em>]</em>) – dtype of the weights tensor.</p></li>
<li><p><strong>lengths_dtype</strong> (<em>torch.dtype</em>) – dtype of the lengths tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>empty KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty_like">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">empty_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kjt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty_like" title="Link to this definition">#</a></dt>
<dd><dl class="simple">
<dt>original usage:</dt><dd><p>Constructs an empty KeyedJaggedTensor with the same device and dtypes as the input KeyedJaggedTensor.
this perserves stride/stride_per_key_per_rank but the actual data (values, lengths, etc.) is empty</p>
</dd>
<dt>device-copy usage:</dt><dd><p>Constructs an empty KeyedJaggedTensor with the empty tensors on the new device</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kjt</strong> (<a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><em>KeyedJaggedTensor</em></a>) – input KeyedJaggedTensor.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>torch.device</em><em>]</em>) – device on which the KeyedJaggedTensor will be placed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>empty KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_jt_dict">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_jt_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">jt_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><span class="pre">JaggedTensor</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_jt_dict" title="Link to this definition">#</a></dt>
<dd><p>Constructs a KeyedJaggedTensor from a dictionary of JaggedTensors.
Automatically calls <cite>kjt.sync()</cite> on newly created KJT.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will ONLY work if the JaggedTensors all
have the same “implicit” batch_size dimension.</p>
</div>
<p>Basically, we can visualize JaggedTensors as 2-D tensors
of the format of [batch_size x variable_feature_dim].
In the case, we have some batch without a feature value,
the input JaggedTensor could just not include any values.</p>
<p>But KeyedJaggedTensor (by default) typically pad “None”
so that all the JaggedTensors stored in the KeyedJaggedTensor
have the same batch_size dimension. That is, in the case,
the JaggedTensor input didn’t automatically pad
for the empty batches, this function would error / not work.</p>
<p>Consider the visualization of the following KeyedJaggedTensor:
#              0       1        2  &lt;– dim_1
# “Feature0”   [V0,V1] None    [V2]
# “Feature1”   [V3]    [V4]    [V5,V6,V7]
#   ^
#  dim_0</p>
<dl class="simple">
<dt>Now if the input jt_dict = {</dt><dd><p># “Feature0”   [V0,V1] [V2]
# “Feature1”   [V3]    [V4]    [V5,V6,V7]</p>
</dd>
</dl>
<p>} and the “None” is left out from each JaggedTensor,
then this function would fail as we would not correctly
be able to pad “None” as it does not technically know
the correct batch / place to pad within the JaggedTensor.</p>
<p>Essentially, the lengths Tensor inferred by this function
would be [2, 1, 1, 1, 3] indicating variable batch_size
dim_1 violates the existing assumption / precondition
that KeyedJaggedTensor’s should have fixed batch_size dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>jt_dict</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><em>JaggedTensor</em></a><em>]</em>) – dictionary of JaggedTensors.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>constructed KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_lengths_sync">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_lengths_sync</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride_per_key_per_rank</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_lengths_sync" title="Link to this definition">#</a></dt>
<dd><p>Constructs a KeyedJaggedTensor from a list of keys, lengths, and offsets.
Same as <cite>from_offsets_sync</cite> except lengths are used instead of offsets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keys</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of keys.</p></li>
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – values tensor in dense representation.</p></li>
<li><p><strong>lengths</strong> (<em>torch.Tensor</em>) – jagged slices, represented as lengths.</p></li>
<li><p><strong>weights</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – if the values have weights. Tensor with the
same shape as values.</p></li>
<li><p><strong>stride</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – number of examples per batch.</p></li>
<li><p><strong>stride_per_key_per_rank</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em><em>]</em>) – batch size
(number of examples) per key per rank, with the outer list representing the
keys and the inner list representing the values.</p></li>
<li><p><strong>inverse_indices</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em><em>]</em>) – inverse indices to
expand deduplicated embedding output for variable stride per key.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>constructed KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_offsets_sync">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_offsets_sync</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride_per_key_per_rank</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_offsets_sync" title="Link to this definition">#</a></dt>
<dd><p>Constructs a KeyedJaggedTensor from a list of keys, values, and offsets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keys</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of keys.</p></li>
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – values tensor in dense representation.</p></li>
<li><p><strong>offsets</strong> (<em>torch.Tensor</em>) – jagged slices, represented as cumulative offsets.</p></li>
<li><p><strong>weights</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – if the values have weights. Tensor with the
same shape as values.</p></li>
<li><p><strong>stride</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – number of examples per batch.</p></li>
<li><p><strong>stride_per_key_per_rank</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em><em>]</em>) – batch size
(number of examples) per key per rank, with the outer list representing the
keys and the inner list representing the values.</p></li>
<li><p><strong>inverse_indices</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>torch.Tensor</em><em>]</em><em>]</em>) – inverse indices to
expand deduplicated embedding output for variable stride per key.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>constructed KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.index_per_key">
<span class="sig-name descname"><span class="pre">index_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.index_per_key" title="Link to this definition">#</a></dt>
<dd><p>Returns the index per key of the KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>index per key of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Dict[str, int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.inverse_indices">
<span class="sig-name descname"><span class="pre">inverse_indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.inverse_indices" title="Link to this definition">#</a></dt>
<dd><p>Returns the inverse indices of the KeyedJaggedTensor.
If inverse indices are None, this will throw an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>inverse indices of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[List[str], torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.inverse_indices_or_none">
<span class="sig-name descname"><span class="pre">inverse_indices_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.inverse_indices_or_none" title="Link to this definition">#</a></dt>
<dd><p>Returns the inverse indices of the KeyedJaggedTensor or None if they don’t exist.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>inverse indices of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[Tuple[List[str], torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.keys">
<span class="sig-name descname"><span class="pre">keys</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.keys" title="Link to this definition">#</a></dt>
<dd><p>Returns the keys of the KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>keys of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key">
<span class="sig-name descname"><span class="pre">length_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key" title="Link to this definition">#</a></dt>
<dd><p>Returns the length per key of the KeyedJaggedTensor.
If length per key is None, this will compute it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>length per key of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key_or_none">
<span class="sig-name descname"><span class="pre">length_per_key_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key_or_none" title="Link to this definition">#</a></dt>
<dd><p>Returns the length per key of the KeyedJaggedTensor or None if it hasn’t been computed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>length per key of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths">
<span class="sig-name descname"><span class="pre">lengths</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths" title="Link to this definition">#</a></dt>
<dd><p>Returns the lengths of the KeyedJaggedTensor.
If the lengths are not computed yet, it will compute them.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>lengths of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths_offset_per_key">
<span class="sig-name descname"><span class="pre">lengths_offset_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths_offset_per_key" title="Link to this definition">#</a></dt>
<dd><p>Returns the lengths offset per key of the KeyedJaggedTensor.
If lengths offset per key is None, this will compute it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>lengths offset per key of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths_or_none">
<span class="sig-name descname"><span class="pre">lengths_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths_or_none" title="Link to this definition">#</a></dt>
<dd><p>Returns the lengths of the KeyedJaggedTensor or None if they are not computed yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>lengths of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key">
<span class="sig-name descname"><span class="pre">offset_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key" title="Link to this definition">#</a></dt>
<dd><p>Returns the offset per key of the KeyedJaggedTensor.
If offset per key is None, this will compute it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>offset per key of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key_or_none">
<span class="sig-name descname"><span class="pre">offset_per_key_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key_or_none" title="Link to this definition">#</a></dt>
<dd><p>Returns the offset per key of the KeyedJaggedTensor or None if it hasn’t been computed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>offset per key of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets">
<span class="sig-name descname"><span class="pre">offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets" title="Link to this definition">#</a></dt>
<dd><p>Returns the offsets of the KeyedJaggedTensor.
If the offsets are not computed yet, it will compute them.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>offsets of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets_or_none">
<span class="sig-name descname"><span class="pre">offsets_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets_or_none" title="Link to this definition">#</a></dt>
<dd><p>Returns the offsets of the KeyedJaggedTensor or None if they are not computed yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>offsets of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.permute">
<span class="sig-name descname"><span class="pre">permute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices_tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.permute" title="Link to this definition">#</a></dt>
<dd><p>Permutes the KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – list of indices.</p></li>
<li><p><strong>indices_tensor</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – tensor of indices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>permuted KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.record_stream">
<span class="sig-name descname"><span class="pre">record_stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Stream</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.record_stream" title="Link to this definition">#</a></dt>
<dd><p>See <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html">https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">segments</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.split" title="Link to this definition">#</a></dt>
<dd><p>Splits the KeyedJaggedTensor into a list of KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>segments</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – list of segments.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride" title="Link to this definition">#</a></dt>
<dd><p>Returns the stride of the KeyedJaggedTensor.
If stride is None, this will compute it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>stride of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride_per_key">
<span class="sig-name descname"><span class="pre">stride_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride_per_key" title="Link to this definition">#</a></dt>
<dd><p>Returns the stride per key of the KeyedJaggedTensor.
If stride per key is None, this will compute it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>stride per key of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride_per_key_per_rank">
<span class="sig-name descname"><span class="pre">stride_per_key_per_rank</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride_per_key_per_rank" title="Link to this definition">#</a></dt>
<dd><p>Returns the stride per key per rank of the KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>stride per key per rank of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[List[int]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.sync">
<span class="sig-name descname"><span class="pre">sync</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.sync" title="Link to this definition">#</a></dt>
<dd><p>Synchronizes the KeyedJaggedTensor by computing the offset_per_key and length_per_key.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>synced KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to" title="Link to this definition">#</a></dt>
<dd><p>Returns a copy of KeyedJaggedTensor in the specified device and dtype.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<em>torch.device</em>) – the desired device of the copy.</p></li>
<li><p><strong>non_blocking</strong> (<em>bool</em>) – whether to copy the tensors in a non-blocking fashion.</p></li>
<li><p><strong>dtype</strong> (<em>Optional</em><em>[</em><em>torch.dtype</em><em>]</em>) – the desired data type of the copy.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the copied KeyedJaggedTensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">compute_offsets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor"><span class="pre">JaggedTensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to_dict" title="Link to this definition">#</a></dt>
<dd><p>Returns a dictionary of JaggedTensor for each key.
Will cache result in self._jt_dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>compute_offsets</strong> (<em>str</em>) – compute offsets when true.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of JaggedTensor for each key.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, <a class="reference internal" href="#torchrec.sparse.jagged_tensor.JaggedTensor" title="torchrec.sparse.jagged_tensor.JaggedTensor">JaggedTensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.unsync">
<span class="sig-name descname"><span class="pre">unsync</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><span class="pre">KeyedJaggedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.unsync" title="Link to this definition">#</a></dt>
<dd><p>Unsyncs the KeyedJaggedTensor by clearing the offset_per_key and length_per_key.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>unsynced KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor" title="torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.values">
<span class="sig-name descname"><span class="pre">values</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.values" title="Link to this definition">#</a></dt>
<dd><p>Returns the values of the KeyedJaggedTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>values of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.variable_stride_per_key">
<span class="sig-name descname"><span class="pre">variable_stride_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.variable_stride_per_key" title="Link to this definition">#</a></dt>
<dd><p>Returns whether the KeyedJaggedTensor has variable stride per key.
NOTE: <cite>self._variable_stride_per_key</cite> could be <cite>False</cite> when <cite>self._stride_per_key_per_rank</cite>
is not <cite>None</cite>. It might be assigned to False externally/intentionally, usually the
<cite>self._stride_per_key_per_rank</cite> is trivial.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>whether the KeyedJaggedTensor has variable stride per key.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights">
<span class="sig-name descname"><span class="pre">weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights" title="Link to this definition">#</a></dt>
<dd><p>Returns the weights of the KeyedJaggedTensor.
If weights is None, this will throw an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>weights of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights_or_none">
<span class="sig-name descname"><span class="pre">weights_or_none</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights_or_none" title="Link to this definition">#</a></dt>
<dd><p>Returns the weights of the KeyedJaggedTensor or None if they don’t exist.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>weights of the KeyedJaggedTensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchrec.sparse.jagged_tensor.</span></span><span class="sig-name descname"><span class="pre">KeyedTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="Link to this definition">#</a></dt>
<dd><p>KeyedTensor holds a concatenated list of dense tensors, each of which can be
accessed by a key.</p>
<p>The keyed dimension can be of variable length (length_per_key).
Common use cases uses include storage of pooled embeddings of different dimensions.</p>
<p>Implementation is torch.jit.script-able.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keys</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of keys.</p></li>
<li><p><strong>length_per_key</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – length of each key along key dimension.</p></li>
<li><p><strong>values</strong> (<em>torch.Tensor</em>) – dense tensor, concatenated typically along key dimension.</p></li>
<li><p><strong>key_dim</strong> (<em>int</em>) – key dimension, zero indexed - defaults to 1
(typically B is 0-dimension).</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># kt is KeyedTensor holding</span>

<span class="c1">#                         0           1           2</span>
<span class="c1">#     &quot;Embedding A&quot;    [1,1]       [1,1]        [1,1]</span>
<span class="c1">#     &quot;Embedding B&quot;    [2,1,2]     [2,1,2]      [2,1,2]</span>
<span class="c1">#     &quot;Embedding C&quot;    [3,1,2,3]   [3,1,2,3]    [3,1,2,3]</span>

<span class="n">tensor_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Embedding A&quot;</span><span class="p">,</span> <span class="s2">&quot;Embedding B&quot;</span><span class="p">,</span> <span class="s2">&quot;Embedding C&quot;</span><span class="p">]</span>

<span class="n">kt</span> <span class="o">=</span> <span class="n">KeyedTensor</span><span class="o">.</span><span class="n">from_tensor_list</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">)</span>

<span class="n">kt</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
<span class="c1"># torch.Tensor(</span>
<span class="c1">#     [</span>
<span class="c1">#         [1, 1, 2, 1, 2, 3, 1, 2, 3],</span>
<span class="c1">#         [1, 1, 2, 1, 2, 3, 1, 2, 3],</span>
<span class="c1">#         [1, 1, 2, 1, 2, 3, 1, 2, 3],</span>
<span class="c1">#     ]</span>
<span class="c1"># )</span>

<span class="n">kt</span><span class="p">[</span><span class="s2">&quot;Embedding B&quot;</span><span class="p">]</span>
<span class="c1"># torch.Tensor([[2, 1, 2], [2, 1, 2], [2, 1, 2]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.device">
<span class="sig-name descname"><span class="pre">device</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">device</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.device" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>device of the values tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.device</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.from_tensor_list">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_tensor_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor"><span class="pre">KeyedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.from_tensor_list" title="Link to this definition">#</a></dt>
<dd><p>Create a KeyedTensor from a list of tensors. The tensors are concatenated
along the cat_dim. The keys are used to index the tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keys</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of keys.</p></li>
<li><p><strong>tensors</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – list of tensors.</p></li>
<li><p><strong>key_dim</strong> (<em>int</em>) – key dimension, zero indexed - defaults to 1
(typically B is 0-dimension).</p></li>
<li><p><strong>cat_dim</strong> (<em>int</em>) – dimension along which to concatenate the tensors - defaults</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>keyed tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor">KeyedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.key_dim">
<span class="sig-name descname"><span class="pre">key_dim</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.key_dim" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>key dimension, zero indexed - typically B is 0-dimension.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.keys">
<span class="sig-name descname"><span class="pre">keys</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.keys" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of keys.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.length_per_key">
<span class="sig-name descname"><span class="pre">length_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.length_per_key" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>length of each key along key dimension.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.offset_per_key">
<span class="sig-name descname"><span class="pre">offset_per_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.offset_per_key" title="Link to this definition">#</a></dt>
<dd><p>Get the offset of each key along key dimension.
Compute and cache if not already computed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>offset of each key along key dimension.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.record_stream">
<span class="sig-name descname"><span class="pre">record_stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Stream</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.record_stream" title="Link to this definition">#</a></dt>
<dd><p>See <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html">https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.regroup">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">regroup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keyed_tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor"><span class="pre">KeyedTensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.regroup" title="Link to this definition">#</a></dt>
<dd><p>Regroup a list of KeyedTensors into a list of tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keyed_tensors</strong> (<em>List</em><em>[</em><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor"><em>KeyedTensor</em></a><em>]</em>) – list of KeyedTensors.</p></li>
<li><p><strong>groups</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – list of groups of keys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of tensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.regroup_as_dict">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">regroup_as_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keyed_tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor"><span class="pre">KeyedTensor</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.regroup_as_dict" title="Link to this definition">#</a></dt>
<dd><p>Regroup a list of KeyedTensors into a dictionary of tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keyed_tensors</strong> (<em>List</em><em>[</em><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor"><em>KeyedTensor</em></a><em>]</em>) – list of KeyedTensors.</p></li>
<li><p><strong>groups</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – list of groups of keys.</p></li>
<li><p><strong>keys</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of keys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of tensors.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[str, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor"><span class="pre">KeyedTensor</span></a></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.to" title="Link to this definition">#</a></dt>
<dd><p>Moves the values tensor to the specified device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<em>torch.device</em>) – device to move the values tensor to.</p></li>
<li><p><strong>non_blocking</strong> (<em>bool</em>) – whether to perform the operation asynchronously
(default: False).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>keyed tensor with values tensor moved to the specified device.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#torchrec.sparse.jagged_tensor.KeyedTensor" title="torchrec.sparse.jagged_tensor.KeyedTensor">KeyedTensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.to_dict" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary of tensors keyed by the keys.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Dict[str, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchrec.sparse.jagged_tensor.KeyedTensor.values">
<span class="sig-name descname"><span class="pre">values</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#torchrec.sparse.jagged_tensor.KeyedTensor.values" title="Link to this definition">#</a></dt>
<dd><p>Get the values tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>dense tensor, concatenated typically along key dimension.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="setup-torchrec.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Setting up TorchRec</p>
      </div>
    </a>
    <a class="right-next"
       href="modules-api-reference.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modules</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="setup-torchrec.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Setting up TorchRec</p>
      </div>
    </a>
    <a class="right-next"
       href="modules-api-reference.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modules</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor"><code class="docutils literal notranslate"><span class="pre">JaggedTensor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.device"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.device()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.empty"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.empty()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.from_dense"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.from_dense()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.from_dense_lengths"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.from_dense_lengths()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.lengths"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.lengths()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.lengths_or_none"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.lengths_or_none()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.offsets"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.offsets()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.offsets_or_none"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.offsets_or_none()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.record_stream"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.record_stream()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.to()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_dense"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.to_dense()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_dense_weights"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.to_dense_weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_padded_dense"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.to_padded_dense()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.to_padded_dense_weights"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.to_padded_dense_weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.values"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.values()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.weights"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.JaggedTensor.weights_or_none"><code class="docutils literal notranslate"><span class="pre">JaggedTensor.weights_or_none()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.concat"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.concat()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.copy_"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.copy_()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.device"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.device()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.empty()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty_like"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.empty_like()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_jt_dict"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.from_jt_dict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_lengths_sync"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.from_lengths_sync()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_offsets_sync"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.from_offsets_sync()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.index_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.index_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.inverse_indices"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.inverse_indices()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.inverse_indices_or_none"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.inverse_indices_or_none()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.keys"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.keys()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.length_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key_or_none"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.length_per_key_or_none()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.lengths()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths_offset_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.lengths_offset_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths_or_none"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.lengths_or_none()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.offset_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key_or_none"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.offset_per_key_or_none()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.offsets()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets_or_none"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.offsets_or_none()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.permute"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.permute()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.record_stream"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.record_stream()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.split"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.split()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.stride()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.stride_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride_per_key_per_rank"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.stride_per_key_per_rank()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.sync"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.sync()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.to()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to_dict"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.to_dict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.unsync"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.unsync()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.values"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.values()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.variable_stride_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.variable_stride_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights_or_none"><code class="docutils literal notranslate"><span class="pre">KeyedJaggedTensor.weights_or_none()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor"><code class="docutils literal notranslate"><span class="pre">KeyedTensor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.device"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.device()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.from_tensor_list"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.from_tensor_list()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.key_dim"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.key_dim()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.keys"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.keys()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.length_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.length_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.offset_per_key"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.offset_per_key()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.record_stream"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.record_stream()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.regroup"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.regroup()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.regroup_as_dict"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.regroup_as_dict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.to"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.to()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.to_dict"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.to_dict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchrec.sparse.jagged_tensor.KeyedTensor.values"><code class="docutils literal notranslate"><span class="pre">KeyedTensor.values()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/meta-pytorch/torchrec/edit/main/docs/source/datatypes-api-reference.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="_sources/datatypes-api-reference.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  


<style>
.site-footer {
    padding: 20px 40px;
    height: 60px !important;
}

@media screen and (min-width: 768px) {
    .site-footer {
        padding: 20px 40px;
    }
}

.site-footer .privacy-policy {
    border-top: none;
    margin-top: 0px;
}

.site-footer .privacy-policy .copyright {
    padding-top: 0;
}
</style>


<footer class="site-footer">

    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
           Copyright © 2025 Meta Platforms, Inc
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright Meta Platforms, Inc.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Data Types",
       "headline": "Data Types",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/datatypes-api-reference.html",
       "articleBody": "Data Types# TorchRec contains data types for representing embedding, otherwise known as sparse features. Sparse features are typically indices that are meant to be fed into embedding tables. For a given batch, the number of embedding lookup indices are variable. Therefore, there is a need for a jagged dimension to represent the variable amount of embedding lookup indices for a batch. This section covers the classes for the 3 TorchRec data types for representing sparse features: JaggedTensor, KeyedJaggedTensor, and KeyedTensor. class torchrec.sparse.jagged_tensor.JaggedTensor(*args, **kwargs)# Represents an (optionally weighted) jagged tensor. A JaggedTensor is a tensor with a jagged dimension which is dimension whose slices may be of different lengths. See KeyedJaggedTensor for full example. Implementation is torch.jit.script-able. Note We will NOT do input validation as it\u2019s expensive, you should always pass in the valid lengths, offsets, etc. Parameters: values (torch.Tensor) \u2013 values tensor in dense representation. weights (Optional[torch.Tensor]) \u2013 if values have weights. Tensor with same shape as values. lengths (Optional[torch.Tensor]) \u2013 jagged slices, represented as lengths. offsets (Optional[torch.Tensor]) \u2013 jagged slices, represented as cumulative offsets. device() \u2192 device# Get JaggedTensor device. Returns: the device of the values tensor. Return type: torch.device static empty(is_weighted: bool = False, device: device | None = None, values_dtype: dtype | None = None, weights_dtype: dtype | None = None, lengths_dtype: dtype = torch.int32) \u2192 JaggedTensor# Constructs an empty JaggedTensor. Parameters: is_weighted (bool) \u2013 whether the JaggedTensor has weights. device (Optional[torch.device]) \u2013 device for JaggedTensor. values_dtype (Optional[torch.dtype]) \u2013 dtype for values. weights_dtype (Optional[torch.dtype]) \u2013 dtype for weights. lengths_dtype (torch.dtype) \u2013 dtype for lengths. Returns: empty JaggedTensor. Return type: JaggedTensor static from_dense(values: List[Tensor], weights: List[Tensor] | None = None) \u2192 JaggedTensor# Constructs JaggedTensor from list of tensors as values, with optional weights. lengths will be computed, of shape (B,), where B is len(values) which represents the batch size. Parameters: values (List[torch.Tensor]) \u2013 a list of tensors for dense representation weights (Optional[List[torch.Tensor]]) \u2013 if values have weights, tensor with the same shape as values. Returns: JaggedTensor created from 2D dense tensor. Return type: JaggedTensor Example: values = [ torch.Tensor([1.0]), torch.Tensor(), torch.Tensor([7.0, 8.0]), torch.Tensor([10.0, 11.0, 12.0]), ] weights = [ torch.Tensor([1.0]), torch.Tensor(), torch.Tensor([7.0, 8.0]), torch.Tensor([10.0, 11.0, 12.0]), ] j1 = JaggedTensor.from_dense( values=values, weights=weights, ) # j1 = [[1.0], [], [7.0, 8.0], [10.0, 11.0, 12.0]] static from_dense_lengths(values: Tensor, lengths: Tensor, weights: Tensor | None = None) \u2192 JaggedTensor# Constructs JaggedTensor from values and lengths tensors, with optional weights. Note that lengths is still of shape (B,), where B is the batch size. Parameters: values (torch.Tensor) \u2013 dense representation of values. lengths (torch.Tensor) \u2013 jagged slices, represented as lengths. weights (Optional[torch.Tensor]) \u2013 if values have weights, tensor with the same shape as values. Returns: JaggedTensor created from 2D dense tensor. Return type: JaggedTensor lengths() \u2192 Tensor# Get JaggedTensor lengths. If not computed, compute it from offsets. Returns: the lengths tensor. Return type: torch.Tensor lengths_or_none() \u2192 Tensor | None# Get JaggedTensor lengths. If not computed, return None. Returns: the lengths tensor. Return type: Optional[torch.Tensor] offsets() \u2192 Tensor# Get JaggedTensor offsets. If not computed, compute it from lengths. Returns: the offsets tensor. Return type: torch.Tensor offsets_or_none() \u2192 Tensor | None# Get JaggedTensor offsets. If not computed, return None. Returns: the offsets tensor. Return type: Optional[torch.Tensor] record_stream(stream: Stream) \u2192 None# See https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html to(device: device, non_blocking: bool = False) \u2192 JaggedTensor# Move the JaggedTensor to the specified device. Parameters: device (torch.device) \u2013 the device to move to. non_blocking (bool) \u2013 whether to perform the copy asynchronously. Returns: the moved JaggedTensor. Return type: JaggedTensor to_dense() \u2192 List[Tensor]# Constructs a dense-representation of the JT\u2019s values. Returns: list of tensors. Return type: List[torch.Tensor] Example: values = torch.Tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]) offsets = torch.IntTensor([0, 2, 2, 3, 4, 5, 8]) jt = JaggedTensor(values=values, offsets=offsets) values_list = jt.to_dense() # values_list = [ # torch.tensor([1.0, 2.0]), # torch.tensor([]), # torch.tensor([3.0]), # torch.tensor([4.0]), # torch.tensor([5.0]), # torch.tensor([6.0, 7.0, 8.0]), # ] to_dense_weights() \u2192 List[Tensor] | None# Constructs a dense-representation of the JT\u2019s weights. Returns: list of tensors, None if no weights. Return type: Optional[List[torch.Tensor]] Example: values = torch.Tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]) weights = torch.Tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]) offsets = torch.IntTensor([0, 2, 2, 3, 4, 5, 8]) jt = JaggedTensor(values=values, weights=weights, offsets=offsets) weights_list = jt.to_dense_weights() # weights_list = [ # torch.tensor([0.1, 0.2]), # torch.tensor([]), # torch.tensor([0.3]), # torch.tensor([0.4]), # torch.tensor([0.5]), # torch.tensor([0.6, 0.7, 0.8]), # ] to_padded_dense(desired_length: int | None = None, padding_value: float = 0.0) \u2192 Tensor# Constructs a 2D dense tensor from the JT\u2019s values of shape (B, N,). Note that B is the length of self.lengths() and N is the longest feature length or desired_length. If desired_length \u003e length we will pad with padding_value, otherwise we will select the last value at desired_length. Parameters: desired_length (int) \u2013 the length of the tensor. padding_value (float) \u2013 padding value if we need to pad. Returns: 2d dense tensor. Return type: torch.Tensor Example: values = torch.Tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]) offsets = torch.IntTensor([0, 2, 2, 3, 4, 5, 8]) jt = JaggedTensor(values=values, offsets=offsets) dt = jt.to_padded_dense( desired_length=2, padding_value=10.0, ) # dt = [ # [1.0, 2.0], # [10.0, 10.0], # [3.0, 10.0], # [4.0, 10.0], # [5.0, 10.0], # [6.0, 7.0], # ] to_padded_dense_weights(desired_length: int | None = None, padding_value: float = 0.0) \u2192 Tensor | None# Constructs a 2D dense tensor from the JT\u2019s weights of shape (B, N,). Note that B (batch size) is the length of self.lengths() and N is the longest feature length or desired_length. If desired_length \u003e length we will pad with padding_value, otherwise we will select the last value at desired_length. Like to_padded_dense but for the JT\u2019s weights instead of values. Parameters: desired_length (int) \u2013 the length of the tensor. padding_value (float) \u2013 padding value if we need to pad. Returns: 2d dense tensor, None if no weights. Return type: Optional[torch.Tensor] Example: values = torch.Tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]) weights = torch.Tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]) offsets = torch.IntTensor([0, 2, 2, 3, 4, 5, 8]) jt = JaggedTensor(values=values, weights=weights, offsets=offsets) d_wt = jt.to_padded_dense_weights( desired_length=2, padding_value=1.0, ) # d_wt = [ # [0.1, 0.2], # [1.0, 1.0], # [0.3, 1.0], # [0.4, 1.0], # [0.5, 1.0], # [0.6, 0.7], # ] values() \u2192 Tensor# Get JaggedTensor values. Returns: the values tensor. Return type: torch.Tensor weights() \u2192 Tensor# Get JaggedTensor weights. If None, throw an error. Returns: the weights tensor. Return type: torch.Tensor weights_or_none() \u2192 Tensor | None# Get JaggedTensor weights. If None, return None. Returns: the weights tensor. Return type: Optional[torch.Tensor] class torchrec.sparse.jagged_tensor.KeyedJaggedTensor(*args, **kwargs)# Represents an (optionally weighted) keyed jagged tensor. A KeyedJaggedTensor is a tensor with a jagged dimension which is dimension whose slices may be of different lengths. Keyed on first dimension and jagged on the last dimension. Implementation is torch.jit.script-able. Parameters: keys (List[str]) \u2013 keys to the jagged Tensor. values (torch.Tensor) \u2013 values tensor in dense representation. weights (Optional[torch.Tensor]) \u2013 if the values have weights. Tensor with the same shape as values. lengths (Optional[torch.Tensor]) \u2013 jagged slices, represented as lengths. offsets (Optional[torch.Tensor]) \u2013 jagged slices, represented as cumulative offsets. stride (Optional[int]) \u2013 number of examples per batch. stride_per_key_per_rank (Optional[Union[torch.IntTensor, List[List[int]]]]) \u2013 batch size (number of examples) per key per rank, with the outer list representing the keys and the inner list representing the values. Each value in the inner list represents the number of examples in the batch from the rank of its index in a distributed context. length_per_key (Optional[List[int]]) \u2013 start length for each key. offset_per_key (Optional[List[int]]) \u2013 start offset for each key and final offset. index_per_key (Optional[Dict[str, int]]) \u2013 index for each key. jt_dict (Optional[Dict[str, JaggedTensor]]) \u2013 dictionary of keys to JaggedTensors. Allow ability to make to_dict() lazy/cacheable. inverse_indices (Optional[Tuple[List[str], torch.Tensor]]) \u2013 inverse indices to expand deduplicated embedding output for variable stride per key. Example: # 0 1 2 \u003c-- dim_1 # \"Feature0\" [V0,V1] None [V2] # \"Feature1\" [V3] [V4] [V5,V6,V7] # ^ # dim_0 dim_0: keyed dimension (ie. `Feature0`, `Feature1`) dim_1: optional second dimension (ie. batch size) dim_2: The jagged dimension which has slice lengths between 0-3 in the above example # We represent this data with following inputs: values: torch.Tensor = [V0, V1, V2, V3, V4, V5, V6, V7] # V == any tensor datatype weights: torch.Tensor = [W0, W1, W2, W3, W4, W5, W6, W7] # W == any tensor datatype lengths: torch.Tensor = [2, 0, 1, 1, 1, 3] # representing the jagged slice offsets: torch.Tensor = [0, 2, 2, 3, 4, 5, 8] # offsets from 0 for each jagged slice keys: List[str] = [\"Feature0\", \"Feature1\"] # correspond to each value of dim_0 index_per_key: Dict[str, int] = {\"Feature0\": 0, \"Feature1\": 1} # index for each key offset_per_key: List[int] = [0, 3, 8] # start offset for each key and final offset static concat(kjt_list: List[KeyedJaggedTensor]) \u2192 KeyedJaggedTensor# Concatenates a list of KeyedJaggedTensors into a single KeyedJaggedTensor. Parameters: kjt_list (List[KeyedJaggedTensor]) \u2013 list of KeyedJaggedTensors to be concatenated. Returns: concatenated KeyedJaggedTensor. Return type: KeyedJaggedTensor copy_(kjt: KeyedJaggedTensor, non_blocking: bool = False) \u2192 KeyedJaggedTensor# Copies the values, weights, lengths, and offsets of the input KeyedJaggedTensor to the current KeyedJaggedTensor. Assume host-side meta data like the keys, stride, stride_per_key, etc. are already ready. Parameters: kjt (KeyedJaggedTensor) \u2013 input KeyedJaggedTensor. non_blocking (bool) \u2013 whether to perform the copy asynchronously. Returns: copied KeyedJaggedTensor. Return type: KeyedJaggedTensor device() \u2192 device# Returns the device of the KeyedJaggedTensor. Returns: device of the KeyedJaggedTensor. Return type: torch.device static empty(is_weighted: bool = False, device: device | None = None, values_dtype: dtype | None = None, weights_dtype: dtype | None = None, lengths_dtype: dtype = torch.int32) \u2192 KeyedJaggedTensor# Constructs an empty KeyedJaggedTensor. Parameters: is_weighted (bool) \u2013 whether the KeyedJaggedTensor is weighted or not. device (Optional[torch.device]) \u2013 device on which the KeyedJaggedTensor will be placed. values_dtype (Optional[torch.dtype]) \u2013 dtype of the values tensor. weights_dtype (Optional[torch.dtype]) \u2013 dtype of the weights tensor. lengths_dtype (torch.dtype) \u2013 dtype of the lengths tensor. Returns: empty KeyedJaggedTensor. Return type: KeyedJaggedTensor static empty_like(kjt: KeyedJaggedTensor, device: device | None = None) \u2192 KeyedJaggedTensor# original usage:Constructs an empty KeyedJaggedTensor with the same device and dtypes as the input KeyedJaggedTensor. this perserves stride/stride_per_key_per_rank but the actual data (values, lengths, etc.) is empty device-copy usage:Constructs an empty KeyedJaggedTensor with the empty tensors on the new device Parameters: kjt (KeyedJaggedTensor) \u2013 input KeyedJaggedTensor. device (Optional[torch.device]) \u2013 device on which the KeyedJaggedTensor will be placed. Returns: empty KeyedJaggedTensor. Return type: KeyedJaggedTensor static from_jt_dict(jt_dict: Dict[str, JaggedTensor]) \u2192 KeyedJaggedTensor# Constructs a KeyedJaggedTensor from a dictionary of JaggedTensors. Automatically calls kjt.sync() on newly created KJT. Note This function will ONLY work if the JaggedTensors all have the same \u201cimplicit\u201d batch_size dimension. Basically, we can visualize JaggedTensors as 2-D tensors of the format of [batch_size x variable_feature_dim]. In the case, we have some batch without a feature value, the input JaggedTensor could just not include any values. But KeyedJaggedTensor (by default) typically pad \u201cNone\u201d so that all the JaggedTensors stored in the KeyedJaggedTensor have the same batch_size dimension. That is, in the case, the JaggedTensor input didn\u2019t automatically pad for the empty batches, this function would error / not work. Consider the visualization of the following KeyedJaggedTensor: # 0 1 2 \u003c\u2013 dim_1 # \u201cFeature0\u201d [V0,V1] None [V2] # \u201cFeature1\u201d [V3] [V4] [V5,V6,V7] # ^ # dim_0 Now if the input jt_dict = {# \u201cFeature0\u201d [V0,V1] [V2] # \u201cFeature1\u201d [V3] [V4] [V5,V6,V7] } and the \u201cNone\u201d is left out from each JaggedTensor, then this function would fail as we would not correctly be able to pad \u201cNone\u201d as it does not technically know the correct batch / place to pad within the JaggedTensor. Essentially, the lengths Tensor inferred by this function would be [2, 1, 1, 1, 3] indicating variable batch_size dim_1 violates the existing assumption / precondition that KeyedJaggedTensor\u2019s should have fixed batch_size dimension. Parameters: jt_dict (Dict[str, JaggedTensor]) \u2013 dictionary of JaggedTensors. Returns: constructed KeyedJaggedTensor. Return type: KeyedJaggedTensor static from_lengths_sync(keys: List[str], values: Tensor, lengths: Tensor, weights: Tensor | None = None, stride: int | None = None, stride_per_key_per_rank: List[List[int]] | None = None, inverse_indices: Tuple[List[str], Tensor] | None = None) \u2192 KeyedJaggedTensor# Constructs a KeyedJaggedTensor from a list of keys, lengths, and offsets. Same as from_offsets_sync except lengths are used instead of offsets. Parameters: keys (List[str]) \u2013 list of keys. values (torch.Tensor) \u2013 values tensor in dense representation. lengths (torch.Tensor) \u2013 jagged slices, represented as lengths. weights (Optional[torch.Tensor]) \u2013 if the values have weights. Tensor with the same shape as values. stride (Optional[int]) \u2013 number of examples per batch. stride_per_key_per_rank (Optional[List[List[int]]]) \u2013 batch size (number of examples) per key per rank, with the outer list representing the keys and the inner list representing the values. inverse_indices (Optional[Tuple[List[str], torch.Tensor]]) \u2013 inverse indices to expand deduplicated embedding output for variable stride per key. Returns: constructed KeyedJaggedTensor. Return type: KeyedJaggedTensor static from_offsets_sync(keys: List[str], values: Tensor, offsets: Tensor, weights: Tensor | None = None, stride: int | None = None, stride_per_key_per_rank: List[List[int]] | None = None, inverse_indices: Tuple[List[str], Tensor] | None = None) \u2192 KeyedJaggedTensor# Constructs a KeyedJaggedTensor from a list of keys, values, and offsets. Parameters: keys (List[str]) \u2013 list of keys. values (torch.Tensor) \u2013 values tensor in dense representation. offsets (torch.Tensor) \u2013 jagged slices, represented as cumulative offsets. weights (Optional[torch.Tensor]) \u2013 if the values have weights. Tensor with the same shape as values. stride (Optional[int]) \u2013 number of examples per batch. stride_per_key_per_rank (Optional[List[List[int]]]) \u2013 batch size (number of examples) per key per rank, with the outer list representing the keys and the inner list representing the values. inverse_indices (Optional[Tuple[List[str], torch.Tensor]]) \u2013 inverse indices to expand deduplicated embedding output for variable stride per key. Returns: constructed KeyedJaggedTensor. Return type: KeyedJaggedTensor index_per_key() \u2192 Dict[str, int]# Returns the index per key of the KeyedJaggedTensor. Returns: index per key of the KeyedJaggedTensor. Return type: Dict[str, int] inverse_indices() \u2192 Tuple[List[str], Tensor]# Returns the inverse indices of the KeyedJaggedTensor. If inverse indices are None, this will throw an error. Returns: inverse indices of the KeyedJaggedTensor. Return type: Tuple[List[str], torch.Tensor] inverse_indices_or_none() \u2192 Tuple[List[str], Tensor] | None# Returns the inverse indices of the KeyedJaggedTensor or None if they don\u2019t exist. Returns: inverse indices of the KeyedJaggedTensor. Return type: Optional[Tuple[List[str], torch.Tensor]] keys() \u2192 List[str]# Returns the keys of the KeyedJaggedTensor. Returns: keys of the KeyedJaggedTensor. Return type: List[str] length_per_key() \u2192 List[int]# Returns the length per key of the KeyedJaggedTensor. If length per key is None, this will compute it. Returns: length per key of the KeyedJaggedTensor. Return type: List[int] length_per_key_or_none() \u2192 List[int] | None# Returns the length per key of the KeyedJaggedTensor or None if it hasn\u2019t been computed. Returns: length per key of the KeyedJaggedTensor. Return type: List[int] lengths() \u2192 Tensor# Returns the lengths of the KeyedJaggedTensor. If the lengths are not computed yet, it will compute them. Returns: lengths of the KeyedJaggedTensor. Return type: torch.Tensor lengths_offset_per_key() \u2192 List[int]# Returns the lengths offset per key of the KeyedJaggedTensor. If lengths offset per key is None, this will compute it. Returns: lengths offset per key of the KeyedJaggedTensor. Return type: List[int] lengths_or_none() \u2192 Tensor | None# Returns the lengths of the KeyedJaggedTensor or None if they are not computed yet. Returns: lengths of the KeyedJaggedTensor. Return type: torch.Tensor offset_per_key() \u2192 List[int]# Returns the offset per key of the KeyedJaggedTensor. If offset per key is None, this will compute it. Returns: offset per key of the KeyedJaggedTensor. Return type: List[int] offset_per_key_or_none() \u2192 List[int] | None# Returns the offset per key of the KeyedJaggedTensor or None if it hasn\u2019t been computed. Returns: offset per key of the KeyedJaggedTensor. Return type: List[int] offsets() \u2192 Tensor# Returns the offsets of the KeyedJaggedTensor. If the offsets are not computed yet, it will compute them. Returns: offsets of the KeyedJaggedTensor. Return type: torch.Tensor offsets_or_none() \u2192 Tensor | None# Returns the offsets of the KeyedJaggedTensor or None if they are not computed yet. Returns: offsets of the KeyedJaggedTensor. Return type: torch.Tensor permute(indices: List[int], indices_tensor: Tensor | None = None) \u2192 KeyedJaggedTensor# Permutes the KeyedJaggedTensor. Parameters: indices (List[int]) \u2013 list of indices. indices_tensor (Optional[torch.Tensor]) \u2013 tensor of indices. Returns: permuted KeyedJaggedTensor. Return type: KeyedJaggedTensor record_stream(stream: Stream) \u2192 None# See https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html split(segments: List[int]) \u2192 List[KeyedJaggedTensor]# Splits the KeyedJaggedTensor into a list of KeyedJaggedTensor. Parameters: segments (List[int]) \u2013 list of segments. Returns: list of KeyedJaggedTensor. Return type: List[KeyedJaggedTensor] stride() \u2192 int# Returns the stride of the KeyedJaggedTensor. If stride is None, this will compute it. Returns: stride of the KeyedJaggedTensor. Return type: int stride_per_key() \u2192 List[int]# Returns the stride per key of the KeyedJaggedTensor. If stride per key is None, this will compute it. Returns: stride per key of the KeyedJaggedTensor. Return type: List[int] stride_per_key_per_rank() \u2192 List[List[int]]# Returns the stride per key per rank of the KeyedJaggedTensor. Returns: stride per key per rank of the KeyedJaggedTensor. Return type: List[List[int]] sync() \u2192 KeyedJaggedTensor# Synchronizes the KeyedJaggedTensor by computing the offset_per_key and length_per_key. Returns: synced KeyedJaggedTensor. Return type: KeyedJaggedTensor to(device: device, non_blocking: bool = False, dtype: dtype | None = None) \u2192 KeyedJaggedTensor# Returns a copy of KeyedJaggedTensor in the specified device and dtype. Parameters: device (torch.device) \u2013 the desired device of the copy. non_blocking (bool) \u2013 whether to copy the tensors in a non-blocking fashion. dtype (Optional[torch.dtype]) \u2013 the desired data type of the copy. Returns: the copied KeyedJaggedTensor. Return type: KeyedJaggedTensor to_dict(compute_offsets: bool = True) \u2192 Dict[str, JaggedTensor]# Returns a dictionary of JaggedTensor for each key. Will cache result in self._jt_dict. Parameters: compute_offsets (str) \u2013 compute offsets when true. Returns: dictionary of JaggedTensor for each key. Return type: Dict[str, JaggedTensor] unsync() \u2192 KeyedJaggedTensor# Unsyncs the KeyedJaggedTensor by clearing the offset_per_key and length_per_key. Returns: unsynced KeyedJaggedTensor. Return type: KeyedJaggedTensor values() \u2192 Tensor# Returns the values of the KeyedJaggedTensor. Returns: values of the KeyedJaggedTensor. Return type: torch.Tensor variable_stride_per_key() \u2192 bool# Returns whether the KeyedJaggedTensor has variable stride per key. NOTE: self._variable_stride_per_key could be False when self._stride_per_key_per_rank is not None. It might be assigned to False externally/intentionally, usually the self._stride_per_key_per_rank is trivial. Returns: whether the KeyedJaggedTensor has variable stride per key. Return type: bool weights() \u2192 Tensor# Returns the weights of the KeyedJaggedTensor. If weights is None, this will throw an error. Returns: weights of the KeyedJaggedTensor. Return type: torch.Tensor weights_or_none() \u2192 Tensor | None# Returns the weights of the KeyedJaggedTensor or None if they don\u2019t exist. Returns: weights of the KeyedJaggedTensor. Return type: torch.Tensor class torchrec.sparse.jagged_tensor.KeyedTensor(*args, **kwargs)# KeyedTensor holds a concatenated list of dense tensors, each of which can be accessed by a key. The keyed dimension can be of variable length (length_per_key). Common use cases uses include storage of pooled embeddings of different dimensions. Implementation is torch.jit.script-able. Parameters: keys (List[str]) \u2013 list of keys. length_per_key (List[int]) \u2013 length of each key along key dimension. values (torch.Tensor) \u2013 dense tensor, concatenated typically along key dimension. key_dim (int) \u2013 key dimension, zero indexed - defaults to 1 (typically B is 0-dimension). Example: # kt is KeyedTensor holding # 0 1 2 # \"Embedding A\" [1,1] [1,1] [1,1] # \"Embedding B\" [2,1,2] [2,1,2] [2,1,2] # \"Embedding C\" [3,1,2,3] [3,1,2,3] [3,1,2,3] tensor_list = [ torch.tensor([[1,1]] * 3), torch.tensor([[2,1,2]] * 3), torch.tensor([[3,1,2,3]] * 3), ] keys = [\"Embedding A\", \"Embedding B\", \"Embedding C\"] kt = KeyedTensor.from_tensor_list(keys, tensor_list) kt.values() # torch.Tensor( # [ # [1, 1, 2, 1, 2, 3, 1, 2, 3], # [1, 1, 2, 1, 2, 3, 1, 2, 3], # [1, 1, 2, 1, 2, 3, 1, 2, 3], # ] # ) kt[\"Embedding B\"] # torch.Tensor([[2, 1, 2], [2, 1, 2], [2, 1, 2]]) device() \u2192 device# Returns: device of the values tensor. Return type: torch.device static from_tensor_list(keys: List[str], tensors: List[Tensor], key_dim: int = 1, cat_dim: int = 1) \u2192 KeyedTensor# Create a KeyedTensor from a list of tensors. The tensors are concatenated along the cat_dim. The keys are used to index the tensors. Parameters: keys (List[str]) \u2013 list of keys. tensors (List[torch.Tensor]) \u2013 list of tensors. key_dim (int) \u2013 key dimension, zero indexed - defaults to 1 (typically B is 0-dimension). cat_dim (int) \u2013 dimension along which to concatenate the tensors - defaults Returns: keyed tensor. Return type: KeyedTensor key_dim() \u2192 int# Returns: key dimension, zero indexed - typically B is 0-dimension. Return type: int keys() \u2192 List[str]# Returns: list of keys. Return type: List[str] length_per_key() \u2192 List[int]# Returns: length of each key along key dimension. Return type: List[int] offset_per_key() \u2192 List[int]# Get the offset of each key along key dimension. Compute and cache if not already computed. Returns: offset of each key along key dimension. Return type: List[int] record_stream(stream: Stream) \u2192 None# See https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html static regroup(keyed_tensors: List[KeyedTensor], groups: List[List[str]]) \u2192 List[Tensor]# Regroup a list of KeyedTensors into a list of tensors. Parameters: keyed_tensors (List[KeyedTensor]) \u2013 list of KeyedTensors. groups (List[List[str]]) \u2013 list of groups of keys. Returns: list of tensors. Return type: List[torch.Tensor] static regroup_as_dict(keyed_tensors: List[KeyedTensor], groups: List[List[str]], keys: List[str]) \u2192 Dict[str, Tensor]# Regroup a list of KeyedTensors into a dictionary of tensors. Parameters: keyed_tensors (List[KeyedTensor]) \u2013 list of KeyedTensors. groups (List[List[str]]) \u2013 list of groups of keys. keys (List[str]) \u2013 list of keys. Returns: dictionary of tensors. Return type: Dict[str, torch.Tensor] to(device: device, non_blocking: bool = False) \u2192 KeyedTensor# Moves the values tensor to the specified device. Parameters: device (torch.device) \u2013 device to move the values tensor to. non_blocking (bool) \u2013 whether to perform the operation asynchronously (default: False). Returns: keyed tensor with values tensor moved to the specified device. Return type: KeyedTensor to_dict() \u2192 Dict[str, Tensor]# Returns: dictionary of tensors keyed by the keys. Return type: Dict[str, torch.Tensor] values() \u2192 Tensor# Get the values tensor. Returns: dense tensor, concatenated typically along key dimension. Return type: torch.Tensor",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/datatypes-api-reference.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>